{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38096fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re                                     #regular expression: used to remove all symbols except alphanumeric from a string\n",
    "import time\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer                           # to convert text -> words -> single number\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences                   #to pad the vectors, so as to make equal size for all\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, SimpleRNN\n",
    "from keras.utils import to_categorical                                  #interger encoded class labes -> one hot encoding array\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26103a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('twitter_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "566a6a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>...</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697200650592256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199560069120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199312482304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697197118861312</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697196967903232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               candidate  candidate_confidence relevant_yn  \\\n",
       "0   1  No candidate mentioned                   1.0         yes   \n",
       "1   2            Scott Walker                   1.0         yes   \n",
       "2   3  No candidate mentioned                   1.0         yes   \n",
       "3   4  No candidate mentioned                   1.0         yes   \n",
       "4   5            Donald Trump                   1.0         yes   \n",
       "\n",
       "   relevant_yn_confidence sentiment  sentiment_confidence     subject_matter  \\\n",
       "0                     1.0   Neutral                0.6578  None of the above   \n",
       "1                     1.0  Positive                0.6333  None of the above   \n",
       "2                     1.0   Neutral                0.6629  None of the above   \n",
       "3                     1.0  Positive                1.0000  None of the above   \n",
       "4                     1.0  Positive                0.7045  None of the above   \n",
       "\n",
       "   subject_matter_confidence candidate_gold  ... relevant_yn_gold  \\\n",
       "0                     1.0000            NaN  ...              NaN   \n",
       "1                     1.0000            NaN  ...              NaN   \n",
       "2                     0.6629            NaN  ...              NaN   \n",
       "3                     0.7039            NaN  ...              NaN   \n",
       "4                     1.0000            NaN  ...              NaN   \n",
       "\n",
       "  retweet_count  sentiment_gold subject_matter_gold  \\\n",
       "0             5             NaN                 NaN   \n",
       "1            26             NaN                 NaN   \n",
       "2            27             NaN                 NaN   \n",
       "3           138             NaN                 NaN   \n",
       "4           156             NaN                 NaN   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...         NaN   \n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...         NaN   \n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...         NaN   \n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...         NaN   \n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...         NaN   \n",
       "\n",
       "               tweet_created            tweet_id  tweet_location  \\\n",
       "0  2015-08-07 09:54:46 -0700  629697200650592256             NaN   \n",
       "1  2015-08-07 09:54:46 -0700  629697199560069120             NaN   \n",
       "2  2015-08-07 09:54:46 -0700  629697199312482304             NaN   \n",
       "3  2015-08-07 09:54:45 -0700  629697197118861312           Texas   \n",
       "4  2015-08-07 09:54:45 -0700  629697196967903232             NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0                       Quito  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3  Central Time (US & Canada)  \n",
       "4                     Arizona  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fefa2630",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7b9600f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>RT @daveweigel: I believe that the phrase \"If ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9413</th>\n",
       "      <td>RT @jsc1835: Chris Christie - You want to incr...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>RT @kharyp: When #HillaryClinton calls men \"Fa...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>Oooh, so Fox News also doesn't want Trump to b...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7501</th>\n",
       "      <td>Perfect #GOPDebate  https://t.co/r5OZZtaeAb</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment\n",
       "613   RT @daveweigel: I believe that the phrase \"If ...  Negative\n",
       "9413  RT @jsc1835: Chris Christie - You want to incr...  Negative\n",
       "2113  RT @kharyp: When #HillaryClinton calls men \"Fa...  Negative\n",
       "747   Oooh, so Fox News also doesn't want Trump to b...   Neutral\n",
       "7501        Perfect #GOPDebate  https://t.co/r5OZZtaeAb  Positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "111b8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].apply(lambda x: x.lower())      #converting all tweets to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f1aa6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @nancyleegrahn: how did everyone feel about...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @scottwalker: didn't catch the full #gopdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @tjmshow: no mention of tamir rice and the ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @robgeorge: that carly fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @danscavino: #gopdebate w/ @realdonaldtrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  rt @nancyleegrahn: how did everyone feel about...   Neutral\n",
       "1  rt @scottwalker: didn't catch the full #gopdeb...  Positive\n",
       "2  rt @tjmshow: no mention of tamir rice and the ...   Neutral\n",
       "3  rt @robgeorge: that carly fiorina is trending ...  Positive\n",
       "4  rt @danscavino: #gopdebate w/ @realdonaldtrump...  Positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f585dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']= data.text.apply(lambda x:x[x.find(':')+1:].strip())                              \n",
    "\n",
    "\n",
    "#x.find(':') will return index of the first occurence of ':' in the text otherwise (if not found) returns -1\n",
    "#x[x.find(':')+1:] selects the text just after the ':' index to the end of the text\n",
    "#strip() function removes and starting and trailing whitespaces from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc478672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how did everyone feel about the climate change...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>didn't catch the full #gopdebate last night. h...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no mention of tamir rice and the #gopdebate wa...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that carly fiorina is trending -- hours after ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#gopdebate w/ @realdonaldtrump delivered the h...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  how did everyone feel about the climate change...   Neutral\n",
       "1  didn't catch the full #gopdebate last night. h...  Positive\n",
       "2  no mention of tamir rice and the #gopdebate wa...   Neutral\n",
       "3  that carly fiorina is trending -- hours after ...  Positive\n",
       "4  #gopdebate w/ @realdonaldtrump delivered the h...  Positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f871755",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data.text.apply(lambda x: re.sub('[^a-zA-Z0-9\\s]','',x) )   \n",
    "\n",
    "#re.sub = substitution.  \"^\"= Not\n",
    "#means substitute all, Not(^) a to z, A to Z, 0 to 9 & white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afd58423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how did everyone feel about the climate change...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>didnt catch the full gopdebate last night here...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no mention of tamir rice and the gopdebate was...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that carly fiorina is trending  hours after he...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gopdebate w realdonaldtrump delivered the high...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  how did everyone feel about the climate change...   Neutral\n",
       "1  didnt catch the full gopdebate last night here...  Positive\n",
       "2  no mention of tamir rice and the gopdebate was...   Neutral\n",
       "3  that carly fiorina is trending  hours after he...  Positive\n",
       "4  gopdebate w realdonaldtrump delivered the high...  Positive"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53e25d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral Sentiment observations: 6284\n",
      "Positive Sentiment observations: 4472\n",
      "Negative Sentiment observations: 16986\n",
      "Size of overall data 27742\n"
     ]
    }
   ],
   "source": [
    "print(\"Neutral Sentiment observations:\",data[data['sentiment']=='Neutral'].size)\n",
    "print(\"Positive Sentiment observations:\",data[data['sentiment']=='Positive'].size)\n",
    "print(\"Negative Sentiment observations:\",data[data['sentiment']=='Negative'].size)\n",
    "print(\"Size of overall data\", data.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f88f7a1",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d8d72d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_words = 2000                                         #maximum number of unique words in vocabulary\n",
    "\n",
    "tokeniser = Tokenizer(num_words = frequent_words, split=' ')  #creats object of tokenizer with considering most 2000 frequent words\n",
    "\n",
    "tokeniser.fit_on_texts(data['text'].values)                   #learns from the data,creates a list of all words, then creates a \n",
    "                                                              #dictionary keeping count of each word, and finally considering \n",
    "                                                              #the most frequent 2000 words only\n",
    "\n",
    "X = tokeniser.texts_to_sequences(data['text'].values)         #convert the text data into sequences of numbers,returns a list\n",
    "                                                              #only for the most frequent 2000 words as learned earlier\n",
    "\n",
    "X=pad_sequences(X)                                            #pads all the vectors by 0 in start, to the \n",
    "                                                              #maximum leangth in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeec30f",
   "metadata": {},
   "source": [
    "\n",
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6df5da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Embd_vec_dim = 128                                              #tells length of the word embedded vector\n",
    "lstm_out = 196                                                  #tells number of LSTM units in LSTM layer\n",
    "\n",
    "model = Sequential()                                            #linear stack of layers\n",
    "\n",
    "model.add(Embedding(frequent_words,Embd_vec_dim,input_length= X.shape[1]))    \n",
    "                                                                #embedding layer for words(converted to numbers) vectorization\n",
    "\n",
    "model.add(SpatialDropout1D(0.4))                               #Droupout layer, to prevent overfitting, randomly drops 40%\n",
    "                                                                #features while training\n",
    "    \n",
    "model.add(LSTM(lstm_out,dropout=0.2, recurrent_dropout=0.2))   #LSTM with dropout\n",
    "\n",
    "model.add(Dense(3, activation = 'softmax'))                     #softmax layer for 3 classes (positive, Neutral, Negative)\n",
    "\n",
    "\n",
    "#############################################################################################################################\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "                                           \n",
    "#configures the model as defining loss, optimiser and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcc304bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 28, 128)           256000    \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spati  (None, 28, 128)           0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 196)               63700     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 591       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320291 (1.22 MB)\n",
      "Trainable params: 320291 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830159de",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Creating Train Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b131cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(data['sentiment']).values         #one hot encoded array in the form [Negative, Neutral, Positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68c25248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9709, 28) (9709, 3)\n",
      "(4162, 28) (4162, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state =42)  \n",
    "                                                                    #random_state control randomness and reproducability of data\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b287b0f5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77994c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "304/304 - 46s - loss: 0.8479 - accuracy: 0.6286 - 46s/epoch - 151ms/step\n",
      "Epoch 2/10\n",
      "304/304 - 37s - loss: 0.7269 - accuracy: 0.6763 - 37s/epoch - 121ms/step\n",
      "Epoch 3/10\n",
      "304/304 - 38s - loss: 0.6664 - accuracy: 0.7010 - 38s/epoch - 126ms/step\n",
      "Epoch 4/10\n",
      "304/304 - 38s - loss: 0.6268 - accuracy: 0.7216 - 38s/epoch - 124ms/step\n",
      "Epoch 5/10\n",
      "304/304 - 878s - loss: 0.5901 - accuracy: 0.7380 - 878s/epoch - 3s/step\n",
      "Epoch 6/10\n",
      "304/304 - 32s - loss: 0.5628 - accuracy: 0.7526 - 32s/epoch - 104ms/step\n",
      "Epoch 7/10\n",
      "304/304 - 38s - loss: 0.5295 - accuracy: 0.7662 - 38s/epoch - 124ms/step\n",
      "Epoch 8/10\n",
      "304/304 - 37s - loss: 0.5085 - accuracy: 0.7761 - 37s/epoch - 123ms/step\n",
      "Epoch 9/10\n",
      "304/304 - 38s - loss: 0.4857 - accuracy: 0.7875 - 38s/epoch - 124ms/step\n",
      "Epoch 10/10\n",
      "304/304 - 38s - loss: 0.4619 - accuracy: 0.7973 - 38s/epoch - 125ms/step\n"
     ]
    }
   ],
   "source": [
    "batch_size =32                                       #Commonly batch size 16 -128\n",
    "                                                     #for smaller dataset 16-32, for large dataset 64-128   \n",
    "    \n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=10, verbose=2)\n",
    "\n",
    "net=time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d039d980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for model training:  20.321604013442993\n"
     ]
    }
   ],
   "source": [
    "print(\"Total time taken for model training: \",net/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a064a43",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63617e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 1s - loss: 1.0819 - accuracy: 0.3969 - 633ms/epoch - 9ms/step\n",
      "Loss: 1.08\n",
      "accuracy: 0.40\n"
     ]
    }
   ],
   "source": [
    "val_entries = 1000\n",
    "\n",
    "X_validation = X_test[-val_entries:]             #selecting from last 1000 to the end\n",
    "Y_validation = Y_test[-val_entries:]\n",
    "\n",
    "X_test= X_test[:-val_entries]                    #selecting from first to before the last 1000\n",
    "Y_test= Y_test[:-val_entries]\n",
    "\n",
    "\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"Loss: %.2f\" % (score))\n",
    "print(\"accuracy: %.2f\" % (acc))\n",
    "\n",
    "\n",
    "#Note: while running this part of code more then twice it throws and error \"OverflowError: cannot convert float infinity to integer\"\n",
    "#as because we are slicing X_test everytime we run, and create validation set, but after a time there is not sufficient entries\n",
    "#available in the test set itself, so as to create validation set again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0104926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0, 1463,  230,  517,   70,  139,   75,\n",
       "        699,   16,    1, 1999,  549,    3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8168bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0, 1463,  230,  517,   70,  139,   75,\n",
       "         699,   16,    1, 1999,  549,    3]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation[0].reshape(1,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "287c6f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a1e0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
